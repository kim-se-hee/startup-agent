"""
Module: agents/competitor_compare.py (LangGraph ë²„ì „)
Purpose: ê²½ìŸì‚¬ ë¹„êµ ì—ì´ì „íŠ¸ (RAG ìš°ì„ , .env ê¸°ë°˜ í‚¤ ë¡œë”©, LangGraph ê¸°ë°˜)

ìž…ë ¥ State ìš”êµ¬:
state = {
  "tech_summary": {"company": "Zest AI", "summary": "...", "tech_score": 82},
  "market_eval": {
      "competitors": ["Featurespace", "SAS Fraud", "FICO"],
      "market_summary": "...",
      "risk_summary": "..."
  },
  "startup_search": {"docs": [ {"title":"...","url":"...","content":"..."}, ... ]},   # ì„ íƒ
  "market_store": [ {"title":"...","url":"...","content":"..."}, ... ]                 # ì„ íƒ
}

ì¶œë ¥ ë³‘í•©:
state["competition"] = {
  "target": "Zest AI",
  "comparisons": [
    {
      "name": "Featurespace",
      "product_focus": "...",
      "tech_diff": "...",
      "go_to_market": "...",
      "strengths": ["..."],
      "weaknesses": ["..."],
      "positioning": "...",
      "sources": [{"title":"...","url":"..."}]
    },
    ...
  ],
  "differentiation_summary": "íƒ€ê¹ƒ ëŒ€ë¹„ ì°¨ë³„í™” ìš”ì•½",
  "edge_score": 0-100
}
"""
from __future__ import annotations

import os
import json
from typing import Any, Dict, List, Optional, TypedDict
from dataclasses import dataclass
from dotenv import load_dotenv

# .env ë¡œë“œ
load_dotenv()

# LangGraph
try:
    from langgraph.graph import StateGraph, START, END
    LANGGRAPH_AVAILABLE = True
except Exception:
    LANGGRAPH_AVAILABLE = False

# LangChain
try:
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_openai import ChatOpenAI
    LANGCHAIN_CHAIN_AVAILABLE = True
except Exception:
    LANGCHAIN_CHAIN_AVAILABLE = False

# Tavily (ì˜µì…˜)
try:
    from tavily import TavilyClient
    TAVILY_AVAILABLE = True
except Exception:
    TAVILY_AVAILABLE = False

# ----------------------------- State & Config -----------------------------

class ComparisonItem(TypedDict, total=False):
    name: str
    product_focus: str
    tech_diff: str
    go_to_market: str
    strengths: List[str]
    weaknesses: List[str]
    positioning: str
    sources: List[Dict[str, str]]

class CompetitionOutput(TypedDict, total=False):
    target: str
    comparisons: List[ComparisonItem]
    differentiation_summary: str
    edge_score: float

class CompetitorState(TypedDict, total=False):
    tech_summary: Dict[str, Any]
    market_eval: Dict[str, Any]
    startup_search: Dict[str, Any]
    market_store: List[Dict[str, str]]
    competition: CompetitionOutput

@dataclass
class CompetitorConfig:
    model: str = "gpt-4o-mini"
    temperature: float = 0.2
    include_chars: int = 2000
    max_docs_per_comp: int = 6

# ----------------------------- Helpers -----------------------------

def _norm(s: str) -> str:
    return (s or "").strip()


def _get_llm(model: str, temperature: float):
    if not LANGCHAIN_CHAIN_AVAILABLE or not os.getenv("OPENAI_API_KEY"):
        return None
    try:
        return ChatOpenAI(model=model, temperature=temperature)
    except Exception:
        return None


def _llm_json(prompt: str, llm) -> Dict[str, Any]:
    if not llm:
        return _offline_stub()
    try:
        chain = ChatPromptTemplate.from_template("{prompt}") | llm | StrOutputParser()
        txt = chain.invoke({"prompt": prompt})
        return json.loads(txt)
    except Exception:
        return _offline_stub()


def _offline_stub() -> Dict[str, Any]:
    return {
        "comparisons": [
            {
                "name": "Featurespace",
                "product_focus": "ì‹¤ì‹œê°„ ê²°ì œ ì‚¬ê¸°íƒì§€ í”Œëž«í¼",
                "tech_diff": "ì´ìƒíƒì§€ ê¸°ë°˜ì˜ í–‰ë™ í”„ë¡œíŒŒì¼ë§, ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬",
                "go_to_market": "ëŒ€í˜• ê²°ì œì‚¬/ì€í–‰ ì¤‘ì‹¬ ì—”í„°í”„ë¼ì´ì¦ˆ ì„¸ì¼ì¦ˆ",
                "strengths": ["ì‹¤ì‹œê°„ ì„±ëŠ¥", "ëŒ€ê·œëª¨ ë ˆí¼ëŸ°ìŠ¤"],
                "weaknesses": ["êµ¬ì¶• ë¹„ìš©", "ì»¤ìŠ¤í„°ë§ˆì´ì§• ë¶€ë‹´"],
                "positioning": "ì—”í„°í”„ë¼ì´ì¦ˆ ê³ ê¸‰ ì„¸ê·¸ë¨¼íŠ¸",
                "sources": []
            },
            {
                "name": "FICO",
                "product_focus": "ì‹ ìš© ë¦¬ìŠ¤í¬ ë° ì‚¬ê¸°íƒì§€ ì†Œí”„íŠ¸ì›¨ì–´ ì œí’ˆêµ°",
                "tech_diff": "ê·œì¹™+ëª¨ë¸ í˜¼í•©, ê°•ë ¥í•œ ì›Œí¬í”Œë¡œ/ì •ì±… ì—”ì§„",
                "go_to_market": "ê¸ˆìœµê¸°ê´€ ë ˆê±°ì‹œ êµì²´ ë° í™•ìž¥",
                "strengths": ["í’ë¶€í•œ ë„ìž…ì‚¬ë¡€", "ì •ì±… ê´€ë¦¬"],
                "weaknesses": ["ìœ ì—°ì„± ì œí•œ", "ì‹ ê·œ AI ìŠ¤íƒ ëŒ€ì‘ ì†ë„"],
                "positioning": "ë ˆê±°ì‹œ ê°•ìž/ì •ì±… ì¤‘ì‹¬",
                "sources": []
            }
        ],
        "differentiation_summary": "ëŒ€ìƒ ê¸°ì—…ì€ ì‹¤ì‹œê°„ ì¶”ë¡ ê³¼ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì£¼ê¸° ë‹¨ì¶•ìœ¼ë¡œ ìš´ì˜ ë¯¼ì²©ì„±ì„ ê°•ì¡°í•˜ë©°, ì—”í„°í”„ë¼ì´ì¦ˆ ëŒ€ë¹„ TCOë¥¼ ë‚®ì¶”ëŠ” ê²ƒì´ ê°•ì .",
        "edge_score": 76
    }


def _collect_docs_for_entity(state: CompetitorState, entity: str, *, max_docs: int = 6, max_chars: int = 2000) -> List[Dict[str, str]]:
    docs: List[Dict[str, str]] = []
    # 1) market_store ìš°ì„ 
    for d in (state.get("market_store") or []) or []:
        title = _norm(d.get("title", ""))
        url = _norm(d.get("url", ""))
        content = _norm(d.get("content", ""))
        if not content:
            continue
        if entity.lower() in (title + url + content).lower():
            docs.append({"title": title[:240], "url": url, "content": content[:max_chars]})
        if len(docs) >= max_docs:
            return docs
    # 2) startup_search.docs
    if len(docs) < max_docs:
        for d in ((state.get("startup_search") or {}).get("docs") or []):
            title = _norm(d.get("title", ""))
            url = _norm(d.get("url", ""))
            content = _norm(d.get("content", "")) or _norm(d.get("snippet", ""))
            if entity.lower() in (title + url + content).lower():
                docs.append({"title": title[:240], "url": url, "content": content[:max_chars]})
            if len(docs) >= max_docs:
                return docs
    # 3) Tavily ê²€ìƒ‰
    if len(docs) < max_docs and TAVILY_AVAILABLE and os.getenv("TAVILY_API_KEY"):
        try:
            client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
            q = f"{entity} fintech ai product technology customers pricing"
            res = client.search(query=q, max_results=max_docs)
            for r in res.get("results", [])[:max_docs]:
                docs.append({
                    "title": _norm(r.get("title", ""))[:240],
                    "url": _norm(r.get("url", "")),
                    "content": _norm(r.get("content", ""))[:max_chars],
                })
        except Exception:
            pass
    # 4) placeholder
    if not docs:
        docs = [{
            "title": f"{entity} overview",
            "url": "https://www.example.com/competitor",
            "content": f"{entity} provides AI-powered risk analytics and fraud detection.",
        }]
    return docs[:max_docs]

# ----------------------------- Node Factory -----------------------------

def _competitor_node_factory(cfg: CompetitorConfig):
    def node(state: CompetitorState) -> CompetitorState:
        target = _norm(((state.get("tech_summary") or {}).get("company")) or state.get("target_company", "")) or "(unknown)"
        comp_list = (state.get("market_eval") or {}).get("competitors", [])
        
        # ëŒ€ìƒ íšŒì‚¬ë¥¼ ê²½ìŸì‚¬ ëª©ë¡ì—ì„œ ì œì™¸ (ì •ê·œí™”í•˜ì—¬ ë¹„êµ)
        import re
        def normalize_name(name):
            """íšŒì‚¬ ì´ë¦„ ì •ê·œí™” (ê´„í˜¸, ê³µë°± ì œê±°)"""
            name = re.sub(r'\([^)]*\)', '', name).strip()
            name = re.sub(r'\s+', ' ', name).strip()
            return name.lower()
        
        target_normalized = normalize_name(target)
        comp_list = [
            comp for comp in comp_list 
            if normalize_name(comp) != target_normalized
        ]
        
        if not comp_list:
            # ê²½ìŸì‚¬ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ìŸì‚¬ ì‚¬ìš©
            comp_list = ["Competitor A", "Competitor B"]

        packs: Dict[str, List[Dict[str, str]]] = {}
        for comp in comp_list[:6]:
            docs = _collect_docs_for_entity(state, comp, max_docs=cfg.max_docs_per_comp, max_chars=cfg.include_chars)
            packs[comp] = docs

        llm = _get_llm(cfg.model, cfg.temperature)

        prompt = json.dumps({
            "instruction": (
                "ë„ˆëŠ” í•€í…Œí¬ ê²½ìŸì‚¬ ë¶„ì„ê°€ë‹¤. ê° ê²½ìŸì‚¬ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œí’ˆì´ˆì /ê¸°ìˆ ì°¨ë³„ì /GT-M/ê°•ì /ì•½ì /í¬ì§€ì…”ë‹ì„ ìš”ì•½í•˜ë¼. "
                "í—ˆìœ„ ì¶”ì •ì€ ê¸ˆì§€í•˜ê³ , ë¬¸ì„œì— ê·¼ê±° ì—†ëŠ” ë‚´ìš©ì€ ìƒëžµí•˜ë¼. JSONë§Œ ì¶œë ¥í•˜ë¼."
            ),
            "target": target,
            "competitors": list(packs.keys()),
            "docs": packs,
            "output_schema": {
                "comparisons": [
                    {
                        "name": "",
                        "product_focus": "",
                        "tech_diff": "",
                        "go_to_market": "",
                        "strengths": [""],
                        "weaknesses": [""],
                        "positioning": "",
                        "sources": [{"title": "", "url": ""}],
                    }
                ],
                "differentiation_summary": "",
                "edge_score": 0,
            },
        }, ensure_ascii=False)

        data = _llm_json(prompt, llm)

        # edge score ë³´ì • (íƒ€ê¹ƒ ê¸°ìˆ ì ìˆ˜ ê°€ì¤‘)
        try:
            base_edge = float(data.get("edge_score", 0))
        except Exception:
            base_edge = 0.0
        tech_score = float(((state.get("tech_summary") or {}).get("tech_score", 0)) or 0)
        edge_score = min(100.0, max(0.0, 0.7 * base_edge + 0.3 * tech_score))

        # ì†ŒìŠ¤ ì¶•ì•½ (packsì—ì„œ ìƒìœ„ 3ê°œë§Œ)
        comparisons = data.get("comparisons", [])
        for comp in comparisons:
            srcs: List[Dict[str, str]] = []
            name = comp.get("name", "")
            for d in packs.get(name, [])[:3]:
                srcs.append({"title": d.get("title", ""), "url": d.get("url", "")})
            comp["sources"] = srcs

        state["competition"] = {
            "target": target,
            "comparisons": comparisons,
            "differentiation_summary": data.get("differentiation_summary", ""),
            "edge_score": float(round(edge_score, 1)),
        }
        
        # ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("âœ… [4/6] ê²½ìŸì‚¬ ë¶„ì„ ì™„ë£Œ")
        print("="*80)
        print(f"ðŸŽ¯ ëŒ€ìƒ ê¸°ì—…: {target}")
        print(f"ðŸ“Š ê²½ìŸ ìš°ìœ„ ì ìˆ˜: {state['competition']['edge_score']}/100")
        print(f"ðŸ† ê²½ìŸì‚¬ ë¹„êµ: {len(comparisons)}ê°œ")
        for idx, comp in enumerate(comparisons[:3], 1):
            print(f"   {idx}. {comp.get('name', 'N/A')}")
            print(f"      ê°•ì : {', '.join(comp.get('strengths', [])[:2])}")
        print("="*80 + "\n")
        
        return state

    return node

# ----------------------------- Graph Builder -----------------------------

def build_competitor_graph(config: Optional[CompetitorConfig] = None):
    cfg = config or CompetitorConfig()
    if not LANGGRAPH_AVAILABLE:
        raise ImportError("LangGraphê°€ ì„¤ì¹˜ë˜ì–´ ìžˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install langgraph` í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    g = StateGraph(CompetitorState)
    g.add_node("competition", _competitor_node_factory(cfg))
    g.add_edge(START, "competition")
    g.add_edge("competition", END)
    return g.compile()

# ----------------------------- Helper -----------------------------

def run_competitor_compare(state: Dict[str, Any], config: Optional[CompetitorConfig] = None) -> Dict[str, Any]:
    app = build_competitor_graph(config)
    return app.invoke(state)

# ----------------------------- CLI Test -----------------------------
if __name__ == "__main__":
    dummy: CompetitorState = {
        "tech_summary": {"company": "Zest AI", "tech_score": 82},
        "market_eval": {"competitors": ["Featurespace", "FICO"]},
        "startup_search": {"docs": [
            {"title": "Featurespace expands ARIC", "url": "https://ex.com/feats", "content": "Featurespace real-time fraud detection platform ARIC..."},
            {"title": "FICO Falcon overview", "url": "https://ex.com/fico", "content": "FICO fraud management and decisioning..."}
        ]}
    }
    final = run_competitor_compare(dummy)
    from pprint import pprint
    pprint(final.get("competition", {}))
